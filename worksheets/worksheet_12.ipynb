{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 12\n",
    "\n",
    "Name:  Jiahang Li\n",
    "UID: U00295086\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Naive Bayes\n",
    "- Model Evaluation\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "| Attribute A | Attribute B | Attribute C | Class |\n",
    "|-------------|-------------|-------------|-------|\n",
    "| Yes         | Single      | High        | No    |\n",
    "| No          | Married     | Mid         | No    |\n",
    "| No          | Single      | Low         | No    |\n",
    "| Yes         | Married     | High        | No    |\n",
    "| No          | Divorced    | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| Yes         | Divorced    | High        | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "\n",
    "a) Compute the following probabilities:\n",
    "\n",
    "- P(Attribute A = Yes | Class = No)\n",
    "- P(Attribute B = Divorced | Class = Yes)\n",
    "- P(Attribute C = High | Class = No)\n",
    "- P(Attribute C = Mid | Class = Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(Attribute A = Yes | Class = No) = (2/7) = 0.2857\n",
    "P(Attribute B = Divorced | Class = Yes) = (1/3) = 0.3333\n",
    "P(Attribute C = High | Class = No) = (2/7) = 0.2857\n",
    "P(Attribute C = Mid | Class = Yes) = (2/3) = 0.6667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Classify the following unseen records:\n",
    "\n",
    "- (Yes, Married, Mid)\n",
    "- (No, Divorced, High)\n",
    "- (No, Single, High)\n",
    "- (No, Divorced, Low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(Class = Yes | A,B,C) = P(Class = Yes) * P(A | Class = Yes) * P(B | Class = Yes) * P(C | Class = Yes)\n",
    "\n",
    "Similarly, the formula for the posterior probability of Class = No given the attribute values (A,B,C) is:\n",
    "\n",
    "P(Class = No | A,B,C) = P(Class = No) * P(A | Class = No) * P(B | Class = No) * P(C | Class = No)\n",
    "\n",
    "We can use the probabilities we computed in part a) to compute these posterior probabilities.\n",
    "\n",
    "For the first record (Yes, Married, Mid):\n",
    "\n",
    "P(Class = Yes | A,Yes; B,Married; C,Mid) = P(Class = Yes) * P(A = Yes | Class = Yes) * P(B = Married | Class = Yes) * P(C = Mid | Class = Yes) = (3/10) * (0/3) * (1/3) * (0/3) = 0\n",
    "P(Class = No | A,Yes; B,Married; C,Mid) = P(Class = No) * P(A = Yes | Class = No) * P(B = Married | Class = No) * P(C = Mid | Class = No) = (7/10) * (2/7) * (2/7) * (1/7) = 0.0082\n",
    "Therefore, we classify this record as Class = No.\n",
    "\n",
    "For the second record (No, Divorced, High):\n",
    "\n",
    "P(Class = Yes | A,No; B,Divorced; C,High) = P(Class = Yes) * P(A = No | Class = Yes) * P(B = Divorced | Class = Yes) * P(C = High | Class = Yes) = (3/10) * (2/3) * (1/3) * (1/3) = 0.0222\n",
    "P(Class = No | A,No; B,Divorced; C,High) = P(Class = No) * P(A = No | Class = No) * P(B = Divorced | Class = No) * P(C = High | Class = No) = (7/10) * (1/7) * (1/7) * (2/7) = 0.0013\n",
    "Therefore, we classify this record as Class = Yes.\n",
    "\n",
    "For the third record (No, Single, High):\n",
    "\n",
    "P(Class = Yes | A,No; B,Single; C,High) = P(Class = Yes) * P(A = No | Class = Yes) * P(B = Single | Class = Yes) * P(C = High | Class = Yes) = (3/10) * (2/3) * (2/3) * (1/3) = 0.0444\n",
    "P(Class = No | A,No; B,Single; C,High) = P(Class = No) * P(A = No | Class = No) * P(B = Single | Class = No) * P(C = High | Class = No) = (7/10) * (3/7) * (2/7) * (2/7) = 0.0295\n",
    "Therefore, we classify this record as Class = Yes.\n",
    "\n",
    "For the fourth record (No, Divorced, Low):\n",
    "\n",
    "P(Class = Yes | A,No; B,Divorced; C,Low) = P(Class = Yes) * P(A = No | Class = Yes) * P(B = Divorced | Class = Yes) * P(C = Low | Class = Yes) = (3/10) * (2/3) * (1/3) * (1/3) = 0.0222\n",
    "P(Class = No | A,No; B,Divorced; C,Low) = P(Class = No) * P(A = No | Class = No) * P(B = Divorced | Class = No) * P(C = Low | Class = No) = (7/10) * (1/7) * (1/7) * (2/7) = 0.0013\n",
    "Therefore, we classify this record as Class = Yes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "a) Write a function to generate the confusion matrix for a list of actual classes and a list of predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Yes': {'Yes': 2, 'No': 1}, 'No': {'Yes': 3, 'No': 4}}\n"
     ]
    }
   ],
   "source": [
    "actual_class = [\"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\"]\n",
    "predicted_class = [\"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\"]\n",
    "def confusion_matrix(actual, predicted):\n",
    "    # Get the set of unique classes\n",
    "    classes = set(actual)\n",
    "    \n",
    "    # Initialize the confusion matrix\n",
    "    matrix = {c: {c_: 0 for c_ in classes} for c in classes}\n",
    "    \n",
    "    # Count the number of instances for each (actual, predicted) pair\n",
    "    for a, p in zip(actual, predicted):\n",
    "        matrix[a][p] += 1\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "print(confusion_matrix(actual_class, predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Assume you have the following Cost Matrix:\n",
    "\n",
    "|            | predicted = Y | predicted = N |\n",
    "|------------|---------------|---------------|\n",
    "| actual = Y |       -1      |       5       |\n",
    "| actual = N |        10     |       0       |\n",
    "\n",
    "What is the cost of the above classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost(True Positive) = -1\n",
    "cost(False Positive) = 10\n",
    "cost(False Negative) = 5\n",
    "cost(True Negative) = 0\n",
    "total_cost = (-1) + 10 + 5 + 0 = 14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that takes in the actual values, the predictions, and a cost matrix and outputs a cost. Test it on the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(actual, predicted, cost_matrix):\n",
    "    # Get the set of unique classes\n",
    "    classes = set(actual)\n",
    "    \n",
    "    # Initialize the confusion matrix\n",
    "    matrix = {c: {c_: 0 for c_ in classes} for c in classes}\n",
    "    \n",
    "    # Count the number of instances for each (actual, predicted) pair\n",
    "    for a, p in zip(actual, predicted):\n",
    "        matrix[a][p] += 1\n",
    "    \n",
    "    # Compute the total cost\n",
    "    total_cost = 0\n",
    "    for a in classes:\n",
    "        for p in classes:\n",
    "            count = matrix[a][p]\n",
    "            total_cost += count * cost_matrix[a][p]\n",
    "    \n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) What is the difference between a testing set and a validation set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validation set is a subset of the training data that is used to evaluate the model during the training process. The purpose of the validation set is to tune the hyperparameters of the model (e.g., learning rate, regularization strength, number of hidden layers) and to prevent overfitting. During the training process, the model is trained on the training set and then evaluated on the validation set to determine how well it generalizes to new data. This process is repeated multiple times while adjusting the hyperparameters until the model achieves satisfactory performance on the validation set.\n",
    "\n",
    "A testing set is a subset of the data that is held out and not used during the training process. The purpose of the testing set is to evaluate the final performance of the model after the hyperparameters have been tuned and the model has been trained on the full training set. The testing set is used to estimate the generalization error of the model, i.e., how well it performs on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) What are some things you can do to handle the case where you have a highly imbalanced dataset (i.e. there are way more of one class than another). Describe both how you can provide better visibility into the failures of the model and how you can set your model training up for success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to balance the dataset is to either oversample the minority class or undersample the majority class. This can be done using techniques such as random oversampling, random undersampling, or a combination of both. Oversampling involves duplicating examples from the minority class, while undersampling involves removing examples from the majority class. Care must be taken to ensure that the resampling process does not introduce bias in the dataset.\n",
    "\n",
    "Another way to handle imbalanced datasets is to assign different weights to each class during training. This way, the model will give more weight to the minority class during training, making it more likely to learn patterns from that class. For example, you can use inverse class frequency weights, where the weight of each class is the inverse of its frequency in the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}